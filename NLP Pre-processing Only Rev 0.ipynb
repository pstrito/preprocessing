{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk.classify\n",
    "from nltk import NaiveBayesClassifier\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 initializes the dataframe \"df\" and imports the csv into df; \n",
    "# 20 calls getdata to import the csv into the dataframe, 'dfAPI'\n",
    "# 30 removes any duplicate records; duplicate records imply bot records\n",
    "# 40 finds certain words in the strings ('body') and deletes the entire record.  \n",
    "# 50Vader sentiment analyzer\n",
    "# 60 creates a new column called 'compound_bin' from the raw_compound scores\n",
    "# 70 converts the 'raw_compound' data to either a 1, 0 or -1. 1 if nltk sentiment number are >= .1; 0 if -.1 < x < .1 \n",
    "# 80 Converts sentiment ratings into numerical values and put the value into 'sentiment_number'.\n",
    "# 90 Determines the percent correct and incorrect for the Vader sentiment values vs the stocktwits sentiment values\n",
    "# 100 counts how many \"None\" sentiment values are there for the stocktwits sentiment value\n",
    "# 110 This removes every other \"None\" record to reduce the total number of \"None\" rating. This is to make\n",
    "# 115 Provides statistics on sentiments; bullish, none or bearish.\n",
    "# 120 Allows user to manually input value when stocktwits sentiment value is \"None\"\n",
    "# 130 Loads a csv file into the df dfAPI and print out the first 21 records\n",
    "# 140 This will change the modified rating to the nltk rating only when they are opposite to see if it improves the accuracy\n",
    "#number \n",
    "# 150 imports the csv into the dataframe, 'dfAPI'\n",
    "# 160 converts the df columns of body and the label (compound or sentiment_number) into one list for each column\n",
    "#this is needed to be able to create the \n",
    "# 170 divides the whole data set into a 80/20 split into a training set and a test set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 210 takes the test_data list, the test_labels list and the predictions list and puts them into a df\n",
    "\n",
    "\n",
    "# 650 Loads and combines two different dataframes into dfAPI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 initializes the dataframe \"df\" and imports the csv into df; \n",
    "# the argument is the name/address of the file.\n",
    "# https://stackoverflow.com/questions/33440805/pandas-dataframe-read-csv-on-bad-data\n",
    "def getData(name):\n",
    "    df1 = pd.DataFrame() # defines df1 as a dataframe\n",
    "    df1 = pd.read_csv(name, header = 0)\n",
    "    return df1\n",
    "\n",
    "    #df1 = pd.read_csv(name, warn_bad_lines=True, error_bad_lines=False)\n",
    "    #df1 = pd.read_csv(name, nrows = 150, warn_bad_lines=True, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-03-05T21:01:03Z   \n",
      "1   INTC  2021-03-05T21:01:03Z   \n",
      "2   INTC  2021-03-05T21:00:02Z   \n",
      "3   INTC  2021-03-05T20:51:14Z   \n",
      "4   INTC  2021-03-05T20:06:56Z   \n",
      "5   INTC  2021-03-05T19:57:20Z   \n",
      "6   INTC  2021-03-05T19:52:43Z   \n",
      "7   INTC  2021-03-05T19:44:47Z   \n",
      "8   INTC  2021-03-05T19:36:13Z   \n",
      "9   INTC  2021-03-05T19:27:49Z   \n",
      "\n",
      "                                                body followers sentiment  \n",
      "0  $INTC Big Trade - $16 399 800.270 000 shares a...       862      None  \n",
      "1  Large Print $INTC Size: 270000 Price: 60.74 Ti...      5502      None  \n",
      "2  Huge Print $INTC Size: 4033477 Price: 60.74 Ti...      5502      None  \n",
      "3               $AMD common follow ur sibs $INTC $MU        48   Bullish  \n",
      "4                $ITT $INTC $ADBE $OPTT $GLBS  .  .        575   Bullish  \n",
      "5  $INTC Should be thankful we are in this bull m...        21   Bullish  \n",
      "6  @ButterFingerDROPs $INTC had its sell off back...        77      None  \n",
      "7  $INTC  Trading is easy with Buy and Short sign...       162      None  \n",
      "8  $AMD At this rate  this will be left behind by...        11      None  \n",
      "9  I sold all my $AMD shares and moved the money ...       134   Bullish  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20 Calls getData to import the csv into the dataframe, 'dfAPI'\n",
    "#dfAPI = getData(\"tech stockTwit 02232021.csv\")\n",
    "\n",
    "dfAPI = getData(\"tech stockTwit 03112021.csv\")\n",
    "\n",
    "print(dfAPI.head(10))\n",
    "len(dfAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2418"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 30 removes any duplicate records; duplicate records imply bot records\n",
    "dfAPI = dfAPI.drop_duplicates()\n",
    "len(dfAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1699"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 40 finds certain words in the strings ('body') and deletes the entire record.\n",
    "#Note: When the record is deleted the df is re-indexed. The index for the while statement is not so the result is\n",
    "#that the record right after the deleted record is skipped. To remedy the problem the index (i) for the while statement \n",
    "#is decremented by one.\n",
    "#Also, the filtering terms are not case sensitive.\n",
    "\n",
    "import fnmatch\n",
    "\n",
    "data = []\n",
    "counter = 0\n",
    "advert = ['* sec *', '* daily News *', '*Huge Print*', '* Form *', '*SweepCast*', '*Large Print*', \n",
    "          '*Huge Print*', '*8-K*', '*SmartOptions*', '*Big Trade*', '*SEC Form*', '*Notice of Exempt*', \n",
    "          '*created_at*', '*stock news*', '*Trading Zones*', '*Entry:*', '*New Article*', '*ooc.bz*', \n",
    "          '*http*', 'Huge Trade', 'Trading is easy', 'www.', '#wallstreetbets', 'wallstreetbets',\n",
    "          'Huge Trade', '#unitedtraders', 'stockbeep.com'] # words or phrases whose records are to be removed; It is not case sensitive.\n",
    "\n",
    "for a in advert:\n",
    "    i = 0\n",
    "    dfAPI = dfAPI.reset_index(drop = True) # resets the index before each iteration; removes the gaps; resets len(dfAPI)\n",
    "    while i < len(dfAPI):\n",
    "        dat = dfAPI.iloc[i,2] # 2 represents the 'body' column\n",
    "        data = [dat] # sets the string from the df into a list for the fnmatch.filter\n",
    "        #print('index = ', i)\n",
    "        filtered = fnmatch.filter(data, a) # compares the information in the 'body' column with the 'advert' list; it places the matched items in the 'filtered' variable.\n",
    "        #https://www.geeksforgeeks.org/fnmatch-unix-filename-pattern-matching-python/\n",
    "\n",
    "        if len(filtered) != 0: #if returns a True then record needs to be removed\n",
    "            counter += 1\n",
    "            #print('index:', i, dfAPI.iloc[i,2]) # prints the index number and record\n",
    "            #print(filtered, '\\n') # prints the entire record where there was a match (not wildcards were used)    \n",
    "            #print('before drop the next record is:', dfAPI.iloc[i+1, 2], 'i+1 = ', i + 1)\n",
    "            \n",
    "            dfAPI = dfAPI.drop(dfAPI.index[i]) # drops (deletes) the record\n",
    "            \n",
    "            #print('after the record is dropped:', dfAPI.iloc[i,2], 'i = ', i)\n",
    "                \n",
    "            #Note: When the record is dropped there is a change in the 'index' number. after the drop index number\n",
    "            #5 becomes index number 4. Since the counter increments one more time it skips the record right after\n",
    "            #the record that was just checked. That is why it takes multiple runs to remove all of the target\n",
    "            #records. To correct this decrement the index, i, by one\n",
    "                \n",
    "            i -= 1\n",
    "    \n",
    "        i += 1\n",
    "\n",
    "dfAPI = dfAPI.reset_index(drop = True) # resets the index; removes the gaps   \n",
    "len(dfAPI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of clean records in the df are:  1617 \n",
      "\n",
      "  symbol            created_at  \\\n",
      "0   INTC  2021-03-05T20:51:14Z   \n",
      "1   INTC  2021-03-05T20:06:56Z   \n",
      "2   INTC  2021-03-05T19:57:20Z   \n",
      "3   INTC  2021-03-05T19:52:43Z   \n",
      "4   INTC  2021-03-05T19:44:47Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0               $AMD common follow ur sibs $INTC $MU        48   Bullish   \n",
      "1                $ITT $INTC $ADBE $OPTT $GLBS  .  .        575   Bullish   \n",
      "2  $INTC Should be thankful we are in this bull m...        21   Bullish   \n",
      "3  @ButterFingerDROPs $INTC had its sell off back...        77      None   \n",
      "4  $INTC  Trading is easy with Buy and Short sign...       162      None   \n",
      "\n",
      "   raw_compound  \n",
      "0        0.0000  \n",
      "1        0.0000  \n",
      "2        0.6996  \n",
      "3        0.0000  \n",
      "4        0.4404  \n"
     ]
    }
   ],
   "source": [
    "#50 Vader sentiment analyzer\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "f = lambda tweet: vader.polarity_scores(tweet)['compound']\n",
    "\n",
    "dfAPI['raw_compound'] = dfAPI['body'].apply(f)\n",
    "\n",
    "print('The number of clean records in the df are: ', len(dfAPI) , '\\n')\n",
    "print(dfAPI.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-03-05T20:51:14Z   \n",
      "1   INTC  2021-03-05T20:06:56Z   \n",
      "2   INTC  2021-03-05T19:57:20Z   \n",
      "3   INTC  2021-03-05T19:52:43Z   \n",
      "4   INTC  2021-03-05T19:44:47Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0               $AMD common follow ur sibs $INTC $MU        48   Bullish   \n",
      "1                $ITT $INTC $ADBE $OPTT $GLBS  .  .        575   Bullish   \n",
      "2  $INTC Should be thankful we are in this bull m...        21   Bullish   \n",
      "3  @ButterFingerDROPs $INTC had its sell off back...        77      None   \n",
      "4  $INTC  Trading is easy with Buy and Short sign...       162      None   \n",
      "\n",
      "   raw_compound  compound_bin  \n",
      "0        0.0000        0.0000  \n",
      "1        0.0000        0.0000  \n",
      "2        0.6996        0.6996  \n",
      "3        0.0000        0.0000  \n",
      "4        0.4404        0.4404  \n"
     ]
    }
   ],
   "source": [
    "# 60 creates a new column called 'compound_bin' from the raw_compound scores. This creates a column that the raw \n",
    "#where the translated raw compound scores will be placed (either a -1, 0, 1.)\n",
    "\n",
    "dfAPI['compound_bin'] = dfAPI['raw_compound'] \n",
    "\n",
    "#del dfAPI['Unnamed: 0'] # deletes the column named 'Unnamed: 0'\n",
    "\n",
    "print(dfAPI.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     symbol            created_at  \\\n",
      "0      INTC  2021-03-05T20:51:14Z   \n",
      "1      INTC  2021-03-05T20:06:56Z   \n",
      "2      INTC  2021-03-05T19:57:20Z   \n",
      "3      INTC  2021-03-05T19:52:43Z   \n",
      "4      INTC  2021-03-05T19:44:47Z   \n",
      "...     ...                   ...   \n",
      "1694     MU  2021-02-24T12:48:31Z   \n",
      "1695     MU  2021-02-24T12:44:23Z   \n",
      "1696     MU  2021-02-24T12:38:21Z   \n",
      "1697     MU  2021-02-24T12:10:44Z   \n",
      "1698     MU  2021-02-24T12:10:09Z   \n",
      "\n",
      "                                                   body followers sentiment  \\\n",
      "0                  $AMD common follow ur sibs $INTC $MU        48   Bullish   \n",
      "1                   $ITT $INTC $ADBE $OPTT $GLBS  .  .        575   Bullish   \n",
      "2     $INTC Should be thankful we are in this bull m...        21   Bullish   \n",
      "3     @ButterFingerDROPs $INTC had its sell off back...        77      None   \n",
      "4     $INTC  Trading is easy with Buy and Short sign...       162      None   \n",
      "...                                                 ...       ...       ...   \n",
      "1694  $MU today is going to be another back breaker🚀...        37   Bullish   \n",
      "1695    $MU 90 w ay to easy，let&#39;s see 100 this week         1      None   \n",
      "1696  $MU Premarket looking promising  bears can get...        55   Bullish   \n",
      "1697                                 $MU DXI up over 3%        55   Bullish   \n",
      "1698  $MU Looking very good again  buy with conviction.        55   Bullish   \n",
      "\n",
      "      raw_compound  compound_bin  \n",
      "0           0.0000           0.0  \n",
      "1           0.0000           0.0  \n",
      "2           0.6996           1.0  \n",
      "3           0.0000           0.0  \n",
      "4           0.4404           1.0  \n",
      "...            ...           ...  \n",
      "1694        0.0000           0.0  \n",
      "1695        0.0000           0.0  \n",
      "1696        0.4574           1.0  \n",
      "1697        0.0000           0.0  \n",
      "1698        0.4927           1.0  \n",
      "\n",
      "[1617 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# 70 converts the 'raw_compound' data to either a 1, 0 or -1. 1 if nltk sentiment number are >= .1; 0 if -.1 < x < .1 \n",
    "#and -1 if <= -.1 and over-rights the value in compound_bin\n",
    "\n",
    "i = 0\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,5] >= 0.1: # column 5 is 'raw_compound'\n",
    "        dfAPI.iloc[i, 6] =  np.int(dfAPI.iloc[i, 5] + .9) # column 6 is 'compound_bin'\n",
    "        \n",
    "    if dfAPI.iloc[i,5] < .1 and dfAPI.iloc[i, 5] > -.1:\n",
    "        dfAPI.iloc[i, 6] = 0   \n",
    "        \n",
    "    if dfAPI.iloc[i,5] <= -.1:\n",
    "        dfAPI.iloc[i, 6] =  np.int(dfAPI.iloc[i, 5] - .9)\n",
    "    i += 1\n",
    "    \n",
    "print(dfAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     symbol            created_at  \\\n",
      "0      INTC  2021-03-05T20:51:14Z   \n",
      "1      INTC  2021-03-05T20:06:56Z   \n",
      "2      INTC  2021-03-05T19:57:20Z   \n",
      "3      INTC  2021-03-05T19:52:43Z   \n",
      "4      INTC  2021-03-05T19:44:47Z   \n",
      "...     ...                   ...   \n",
      "1694     MU  2021-02-24T12:48:31Z   \n",
      "1695     MU  2021-02-24T12:44:23Z   \n",
      "1696     MU  2021-02-24T12:38:21Z   \n",
      "1697     MU  2021-02-24T12:10:44Z   \n",
      "1698     MU  2021-02-24T12:10:09Z   \n",
      "\n",
      "                                                   body followers sentiment  \\\n",
      "0                  $AMD common follow ur sibs $INTC $MU        48   Bullish   \n",
      "1                   $ITT $INTC $ADBE $OPTT $GLBS  .  .        575   Bullish   \n",
      "2     $INTC Should be thankful we are in this bull m...        21   Bullish   \n",
      "3     @ButterFingerDROPs $INTC had its sell off back...        77      None   \n",
      "4     $INTC  Trading is easy with Buy and Short sign...       162      None   \n",
      "...                                                 ...       ...       ...   \n",
      "1694  $MU today is going to be another back breaker🚀...        37   Bullish   \n",
      "1695    $MU 90 w ay to easy，let&#39;s see 100 this week         1      None   \n",
      "1696  $MU Premarket looking promising  bears can get...        55   Bullish   \n",
      "1697                                 $MU DXI up over 3%        55   Bullish   \n",
      "1698  $MU Looking very good again  buy with conviction.        55   Bullish   \n",
      "\n",
      "      raw_compound  compound_bin  sentiment_number  modified_rating modified?  \n",
      "0           0.0000           0.0               1.0                0        No  \n",
      "1           0.0000           0.0               1.0                0        No  \n",
      "2           0.6996           1.0               1.0                0        No  \n",
      "3           0.0000           0.0               0.0                0        No  \n",
      "4           0.4404           1.0               0.0                0        No  \n",
      "...            ...           ...               ...              ...       ...  \n",
      "1694        0.0000           0.0               1.0                0        No  \n",
      "1695        0.0000           0.0               0.0                0        No  \n",
      "1696        0.4574           1.0               1.0                0        No  \n",
      "1697        0.0000           0.0               1.0                0        No  \n",
      "1698        0.4927           1.0               1.0                0        No  \n",
      "\n",
      "[1617 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# 80 Converts sentiment ratings into numerical values and put the value into 'sentiment_number'.\n",
    "#Stocktwits sentiment rating (bullish or Bearish) is used as the standard;\n",
    "#Stocktwits sentiment rating of 'None' is not used as a standard because people could have simply elected to not enter it.\n",
    "#https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "conditions = [(dfAPI['sentiment'] == 'Bullish'),\n",
    "              (dfAPI['sentiment'] == 'None'),\n",
    "              (dfAPI['sentiment'] == 'Bearish')]\n",
    "\n",
    "values = [1.0, 0.0, -1.0]\n",
    "\n",
    "dfAPI['sentiment_number'] = np.select(conditions, values)\n",
    "\n",
    "dfAPI['modified_rating'] = 0 # adds a column \"modified_rating\" and sets it equal to 0\n",
    "dfAPI['modified?'] = 'No' # adds a column \"modified?\" and sets it equal to 'No'\n",
    "\n",
    "\n",
    "print(dfAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vader percent correct to stocktwits raw data is: 40 %\n",
      "The Vader percent incorrect to stocktwits raw data is: 59 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ncorrect = 0\\nincorrect = 0\\ntotal = len(dfAPI)\\ni = 0\\nwhile i < len(dfAPI):\\n    if dfAPI.iloc[i, 7] == dfAPI.iloc[i, 9]:\\n        correct += 1\\n    else:\\n        incorrect += 1 \\n        \\n    i += 1\\n\\nprint('The Vader percent correct compared to stocktwit enhanced is:', int(100 * correct/total), '%')\\nprint('The Vader percent incorrect compared to stocktwits enhanced is:', int(100 * incorrect/total), '%')\\n\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 90 Determines the percent correct and incorrect for the Vader sentiment values vs the stocktwits sentiment values\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "total = len(dfAPI)\n",
    "i = 0\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i, 6] == dfAPI.iloc[i, 7]: # column 6 is 'compound_bin' and column 7 is 'sentiment_number'\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1 \n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "print('The Vader percent correct to stocktwits raw data is:', int(100 * correct/total), '%')\n",
    "print('The Vader percent incorrect to stocktwits raw data is:', int(100 * incorrect/total), '%')\n",
    "\n",
    "'''\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "total = len(dfAPI)\n",
    "i = 0\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i, 7] == dfAPI.iloc[i, 9]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        incorrect += 1 \n",
    "        \n",
    "    i += 1\n",
    "\n",
    "print('The Vader percent correct compared to stocktwit enhanced is:', int(100 * correct/total), '%')\n",
    "print('The Vader percent incorrect compared to stocktwits enhanced is:', int(100 * incorrect/total), '%')\n",
    "\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of \"None\" stocktwits sentiment values is: 1408\n",
      "The percentage of \"None\" values is: 56.3 %\n"
     ]
    }
   ],
   "source": [
    "# 100 counts how many \"None\" sentiment values are there for the stocktwits sentiment value\n",
    "\n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'None':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The number of \"None\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"None\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records is:  1104\n",
      "The number of \"None\" stocktwits sentiment values is: 294\n",
      "The percentage of \"None\" values is: 26.6 %\n",
      "The number of \"Bullish\" stocktwits sentiment values is: 669\n",
      "The percentage of \"None\" values is: 60.5 %\n",
      "The number of \"Bearish\" stocktwits sentiment values is: 140\n",
      "The percentage of \"None\" values is: 12.6 %\n"
     ]
    }
   ],
   "source": [
    "# 110 This removes every other \"None\" record to reduce the total number of \"None\" rating. This is to make\n",
    "#the 'None' proportions more equal. It also prints the ratios of each sentiment response to the total number\n",
    "#of responses.\n",
    "\n",
    "i = 0\n",
    "counter = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'None':\n",
    "        if i % 2 == 0: #identifies every even index where the sentiment is \"None\"\n",
    "            dfAPI = dfAPI.drop(dfAPI.index[i]) #drops (deletes) the record\n",
    "            \n",
    "    i += 1\n",
    "    \n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'None':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The total number of records is: ', len(dfAPI))\n",
    "print('The number of \"None\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"None\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "\n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'Bullish':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The number of \"Bullish\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"Bullish\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "            \n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'Bearish':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The number of \"Bearish\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"Bearish\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records is:  2500\n",
      "The number of \"None\" stocktwits sentiment values is: 1408\n",
      "The percentage of \"None\" values is: 56.3 %\n",
      "The number of \"Bullish\" stocktwits sentiment values is: 840\n",
      "The percentage of \"Bullish\" values is: 33.6 %\n",
      "The number of \"Bearish\" stocktwits sentiment values is: 169\n",
      "The percentage of \"Bearish\" values is: 6.7 %\n"
     ]
    }
   ],
   "source": [
    "# 115 Provides statistics on sentiments; bullish, none or bearish.\n",
    "\n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'None':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The total number of records is: ', len(dfAPI))\n",
    "print('The number of \"None\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"None\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "\n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'Bullish':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The number of \"Bullish\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"Bullish\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "            \n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(dfAPI):\n",
    "    if dfAPI.iloc[i,4] == 'Bearish':\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The number of \"Bearish\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"Bearish\" values is:', (int(sentiment_number/len(dfAPI) * 1000)/10), '%')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this the first time processing the raw stocktwits data (enter \"n\"/\"N\" or \"y\"/\"Y\")? n\n",
      "Loaded filename: tech stockTwit 03112021 adjusted.csv\n",
      "The csv file was written. File name:  tech stockTwit 03112021 adjusted.csv\n"
     ]
    }
   ],
   "source": [
    "# 120 Allows user to manually input value when stocktwits sentiment value is \"None\"\n",
    "# It counts every 20 edits and gives the user the option to quit. If the user chooses to quit\n",
    "# it breaks from the while look and writes the df to a csv file so all work is saved up to that point.\n",
    "# upon start up it ask if thie is the first time processing the raw data. If no it loads the csv file into\n",
    "# the dataframe and starts where the previous session left off. If \"modified?\" is \"Yes and \"sentiment\" is \"None\"\n",
    "# it skips the record. Therefore it will re-start at the first \"modified?\" is \"No\" and \"sentiment\" is \"None\"\n",
    "\n",
    "import copy\n",
    "\n",
    "filename = \"tech stockTwit 03112021 adjusted.csv\"\n",
    "\n",
    "load = input('Is this the first time processing the raw stocktwits data (enter \"n\"/\"N\" or \"y\"/\"Y\")? ')\n",
    "if load == 'n' or load == 'N' or load == 'no' or load == 'No':\n",
    "    dfAPI = getData(filename)\n",
    "    print('Loaded filename:', filename)\n",
    "else:\n",
    "    \n",
    "    print('ok')\n",
    "    \n",
    "i = 0\n",
    "counter = 0    # counter to see if user want to stop\n",
    "\n",
    "while i < len(dfAPI):\n",
    "#while i < 6:\n",
    "\n",
    "    if dfAPI.iloc[i,4] == 'None' and dfAPI.iloc[i,9] == 'No':\n",
    "        print('\\nindex number:', i, '\\n', dfAPI.iloc[i, 2])\n",
    "        #print('This is the body of the tweet:\\n', dfAPI.iloc[i, 2])\n",
    "        rating = int(input('Enter your rating (1, 0 or -1.):')) \n",
    "        dfAPI.iloc[i,8] = copy.deepcopy(rating) # writes inputed number to the 'modified_rating'\n",
    "        dfAPI.iloc[i,9] = 'Yes' # sets \"modified?\" equal to 'Yes' to identify which records have been modified; so that it can start at the next record at start up\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    elif dfAPI.iloc[i,4] == 'Bearish':\n",
    "    #elif dfAPI.iloc[i,4] == 'Bearish' and dfAPI.iloc[i,9] == 'No': # the second condition is not needed\n",
    "\n",
    "        dfAPI.iloc[i,8] = dfAPI.iloc[i,7] #copies the stocktwits 'sentiment_number' to the 'modified_rating'\n",
    "        \n",
    "    elif dfAPI.iloc[i,4] == 'Bullish':\n",
    "    #elif dfAPI.iloc[i,4] == 'Bullish' and dfAPI.iloc[i,9] == 'No': # the second condition is not needed\n",
    "        \n",
    "        dfAPI.iloc[i,8] = dfAPI.iloc[i,7] #copies the stocktwits 'sentiment_number' to the 'modified_rating'\n",
    "\n",
    "    if counter == 20: # represents 20 edits\n",
    "        quit = input('Do you want to quit? (Enter either a \"y\" or \"Y\") ')\n",
    "        if quit == 'y' or quit == 'Y':\n",
    "            print('You are exiting.')\n",
    "            break\n",
    "        else:\n",
    "            counter = 0 # resets the counter to 0 so there must be another 20 records reviewed and modified \n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "dfAPI.to_csv(filename, index = False)\n",
    "print('The csv file was written. File name: ', filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    symbol            created_at  \\\n",
      "0     INTC  2021-03-05T20:51:14Z   \n",
      "1     INTC  2021-03-05T20:06:56Z   \n",
      "2     INTC  2021-03-05T19:57:20Z   \n",
      "3     INTC  2021-03-05T19:52:43Z   \n",
      "4     INTC  2021-03-05T19:36:13Z   \n",
      "5     INTC  2021-03-05T19:27:49Z   \n",
      "6     INTC  2021-03-05T17:59:24Z   \n",
      "7     INTC  2021-03-05T17:55:23Z   \n",
      "8     INTC  2021-03-05T17:18:29Z   \n",
      "9     INTC  2021-03-05T17:10:52Z   \n",
      "10    INTC  2021-03-05T16:38:58Z   \n",
      "11    INTC  2021-03-05T16:34:59Z   \n",
      "12    INTC  2021-03-05T16:26:43Z   \n",
      "13    INTC  2021-03-05T16:20:24Z   \n",
      "14    INTC  2021-03-05T16:13:29Z   \n",
      "15    INTC  2021-03-05T16:04:50Z   \n",
      "16    INTC  2021-03-05T15:41:40Z   \n",
      "17    INTC  2021-03-05T15:39:51Z   \n",
      "18  symbol            created_at   \n",
      "19    INTC  2021-03-04T23:21:00Z   \n",
      "20    INTC  2021-03-04T23:04:18Z   \n",
      "\n",
      "                                                 body  followers  sentiment  \\\n",
      "0                $AMD common follow ur sibs $INTC $MU         48    Bullish   \n",
      "1                 $ITT $INTC $ADBE $OPTT $GLBS  .  .         575    Bullish   \n",
      "2   $INTC Should be thankful we are in this bull m...         21    Bullish   \n",
      "3   @ButterFingerDROPs $INTC had its sell off back...         77       None   \n",
      "4   $AMD At this rate  this will be left behind by...         11       None   \n",
      "5   I sold all my $AMD shares and moved the money ...        134    Bullish   \n",
      "6   $INTC this is a real 💎 we just don’t tell othe...         21    Bullish   \n",
      "7   $INTC $intc i hope that they will be bankrupte...          1       None   \n",
      "8   $INTC keeping the portfolio respectable today ...          8    Bullish   \n",
      "9   $VZ and $INTC LEAPS I added on dip are saving ...         68       None   \n",
      "10  $INTC People wants to compare this to $AMD   b...          5    Bullish   \n",
      "11  @FuutesRipping $INTC holding up very well in t...        183       None   \n",
      "12                           $INTC $TSN $NUS greenage         91    Bullish   \n",
      "13  @TraderLeibniz @Uncle_Covid @Stock__Twists @Ja...        183       None   \n",
      "14  $INTC this has to be a meg options pin. No oth...         36       None   \n",
      "15                          $INTC this is up...wow...         46       None   \n",
      "16               $INTC .E: 64.51.TP: 73. 58.SL: 59.98         11    Bullish   \n",
      "17    $INTC boomer stock says fuck the broader market          0       None   \n",
      "18                                               body  followers  sentiment   \n",
      "19  @Equalipty @anon101010 Hahahahaha@Shintel. Eve...         12       None   \n",
      "20  $AMD I think $INTC will be trading higher than...         12    Bullish   \n",
      "\n",
      "    raw_compound  compound_bin  sentiment_number  modified_rating modified?  \n",
      "0         0.0000           0.0               1.0              1.0        No  \n",
      "1         0.0000           0.0               1.0              1.0        No  \n",
      "2         0.6996           1.0               1.0              1.0        No  \n",
      "3         0.0000           0.0               0.0              1.0       Yes  \n",
      "4         0.5574           1.0               0.0              1.0       Yes  \n",
      "5         0.0000           0.0               1.0              1.0        No  \n",
      "6         0.0000           0.0               1.0              1.0        No  \n",
      "7         0.4588           1.0               0.0             -1.0       Yes  \n",
      "8         0.8777           1.0               1.0              1.0        No  \n",
      "9        -0.5423          -1.0               0.0              1.0       Yes  \n",
      "10        0.7579           1.0               1.0              1.0        No  \n",
      "11        0.6028           1.0               0.0              1.0       Yes  \n",
      "12        0.0000           0.0               1.0              1.0        No  \n",
      "13        0.2732           1.0               0.0              1.0       Yes  \n",
      "14       -0.2960          -1.0               0.0              1.0       Yes  \n",
      "15        0.0000           0.0               0.0              1.0       Yes  \n",
      "16        0.0000           0.0               1.0              1.0        No  \n",
      "17       -0.5423          -1.0               0.0             -1.0       Yes  \n",
      "18        0.0000           0.0               0.0              0.0        No  \n",
      "19        0.6486           1.0               0.0              1.0       Yes  \n",
      "20        0.0000           0.0               1.0              1.0        No  \n"
     ]
    }
   ],
   "source": [
    "# 130 Loads a csv file named 'filename' into the df dfAPI and print out the first 21 records\n",
    "#filename is defined in #120 above.\n",
    "\n",
    "dfAPI = getData(filename)\n",
    "print(dfAPI.head(21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file was written. File name:  tech stockTwit 02232021 opposite compound_bin vs modified_rating.csv\n"
     ]
    }
   ],
   "source": [
    "# 140 This will change the modified rating to the nltk rating only when they are opposite to see if it improves \n",
    "#the accuracy number \n",
    "\n",
    "new_filename = 'tech stockTwit 02232021 opposite compound_bin vs modified_rating.csv'\n",
    "\n",
    "import copy\n",
    "\n",
    "counter = 0    # counter to see if user want to stop\n",
    "\n",
    "while i < len(dfAPI):\n",
    "\n",
    "    if dfAPI.iloc[i,6] == -1 and dfAPI.iloc[i, 8] == 1:\n",
    "        dfAPI.iloc[i,8] = copy.deepcopy(dfAPI.iloc[i, 6]) # change \"modified rating\" to \"compound_bin\"       \n",
    "        \n",
    "    elif dfAPI.iloc[i,6] == 1 and dfAPI.iloc[i, 8] == -1:\n",
    "        dfAPI.iloc[i,8] = copy.deepcopy(dfAPI.iloc[i, 6]) # change \"modified rating\" to \"compound_bin\"     \n",
    "\n",
    "    i += 1\n",
    "    \n",
    "dfAPI.to_csv(new_filename, index = False)\n",
    "print('The csv file was written. File name: ', new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-02-23T18:37:55Z   \n",
      "1   INTC  2021-02-23T18:10:05Z   \n",
      "2   INTC  2021-02-23T17:41:45Z   \n",
      "3   INTC  2021-02-23T17:36:25Z   \n",
      "4   INTC  2021-02-23T16:55:34Z   \n",
      "5   INTC  2021-02-23T16:51:26Z   \n",
      "6   INTC  2021-02-23T16:35:10Z   \n",
      "7   INTC  2021-02-23T16:15:03Z   \n",
      "8   INTC  2021-02-23T16:03:20Z   \n",
      "9   INTC  2021-02-23T15:26:46Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0  $GOOG $BA $FB $GOOGL $INTC ..Wow _Great !!📈 ga...         1      None   \n",
      "1  $TSLA chart looking like $INTC or $CSCO from t...         1   Bearish   \n",
      "2  $POETF PHOTONICS. Come take a peek. Quick DD a...        33   Bullish   \n",
      "3  $ARWR $INTC $T $INFI added to all of these tod...       261   Bullish   \n",
      "4  $INTC Third Point Sees Enormous Shareholder Va...        12   Bullish   \n",
      "5  $AMD $INTC Intel - From Inventors of the CPU t...        26      None   \n",
      "6  Most profitable trading room  It&#39;s turned ...         0   Bullish   \n",
      "7  Semiconductors on Stock News.https://stocknews...     41199      None   \n",
      "8  $INTC Partnering with Intel to accelerate clou...        12   Bullish   \n",
      "9  $INTC  Trading is easy with Buy and Short sign...       109      None   \n",
      "\n",
      "   raw_compound  compound_bin  sentiment_number  modified_rating modified?  \n",
      "0        0.7243           1.0               0.0              1.0       Yes  \n",
      "1        0.3612           1.0              -1.0             -1.0        No  \n",
      "2        0.7184           1.0               1.0              1.0        No  \n",
      "3        0.0000           0.0               1.0              1.0        No  \n",
      "4        0.5423           1.0               1.0              1.0        No  \n",
      "5        0.4939           1.0               0.0             -1.0       Yes  \n",
      "6        0.8841           1.0               1.0              1.0        No  \n",
      "7        0.0000           0.0               0.0              0.0       Yes  \n",
      "8        0.0000           0.0               1.0              1.0        No  \n",
      "9        0.4404           1.0               0.0              0.0       Yes  \n"
     ]
    }
   ],
   "source": [
    "# 150 imports the csv into the dataframe, 'dfAPI'\n",
    "dfAPI = getData(\"tech stockTwit 02232021 opposite compound_bin vs modified_rating.csv\")\n",
    "print(dfAPI.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of \"None\" stocktwits sentiment values is: 25\n",
      "The percentage of \"None\" values is: 9.7 %\n"
     ]
    }
   ],
   "source": [
    "# 180\n",
    "#counts how many \"None\" sentiment values are there for the stocktwits sentiment value\n",
    "\n",
    "i = 0\n",
    "sentiment_number = 0\n",
    "\n",
    "while i < len(test_labels):\n",
    "    if test_labels[i] == 0.0:\n",
    "        sentiment_number += 1\n",
    "    i += 1\n",
    "\n",
    "print('The number of \"None\" stocktwits sentiment values is:', sentiment_number)\n",
    "print('The percentage of \"None\" values is:', (int(sentiment_number/len(test_labels) * 1000)/10), '%')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This removes the \"stopwords\" and counts the remaining words that are used in the tweets in the dataframe. The \"stopwords\" are considered generic. It also removes specific words identified as sentiment neutral.\n",
    "\n",
    "NOTE: This must be run before the date/time format conversion because the column indexes are changed in the date/time reformating which will cause the column indexes to be wrong here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 340\n",
    "#Given a list of words, remove any words that are in a list of stopwords. (1)\n",
    "\n",
    "def removeStopwords(wordlist, stopwords):\n",
    "    return [w for w in wordlist if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 350\n",
    "#Given a list of words, remove any words in wordlist that are in a list of stopwords. (1)\n",
    "\n",
    "def removeStopwords(wordstring, stopwords):\n",
    "    print(stopwords)\n",
    "    wordlist = wordstring.split()\n",
    "    for w in wordlist:\n",
    "        if w != 'QS':\n",
    "            print(w)\n",
    "    #return [w for w in wordlist if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Readytogo123 @Maddog68 SMART!!! yah I got nutty bought $QS . Been moving weeks. Got 41.75$. Looks promising bounce. So oversold. $AMD $NVDA ok today. You holding $GOOGL ?? Wow.\n"
     ]
    }
   ],
   "source": [
    "#380 from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "text = dfAPI.iloc[0,2]\n",
    "filtered_sentence = remove_stopwords(text)\n",
    "\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'Readytogo123', '@', 'Maddog68', 'SMART', '!', '!', '!', 'yah', 'got', 'nutty', 'bought', '.', 'Been', 'moving', 'weeks', '.', '41.75', '.', 'Looks', 'promising', 'bounce', '.', 'So', 'oversold', '.', 'ok', 'today', '.', 'holding', '?', '?', 'Wow', '.'] \n",
      "\n",
      "@Readytogo123 @Maddog68 SMART!!! yah I got nutty and bought $QS . Been moving down for over two weeks. Got in at 41.75$. Looks promising for a bounce. So oversold. $AMD $NVDA did ok today. You still holding $GOOGL ?? Wow.\n"
     ]
    }
   ],
   "source": [
    "#390 using the gensim and nltk libraries to remove stope words\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# adds $, QS , Got to the stopword list in gensim\n",
    "all_stopwords_gensim = STOPWORDS.union(set(['$', 'QS', 'Got', 'GOOGL', 'AMD', 'NVDA', 'I', 'You']))\n",
    "\n",
    "text = dfAPI.iloc[0,2]\n",
    "text_tokens = word_tokenize(text)\n",
    "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords_gensim]\n",
    "\n",
    "print(tokens_without_sw, '\\n')\n",
    "print(dfAPI.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ Readytogo123 @ Maddog68 SMART ! ! ! yah got nutty bought . Been moving weeks . 41.75 . Looks promising bounce . So oversold . ok today . holding ? ? Wow .'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#400 combines individual words back into one string\n",
    "' '.join(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#410\n",
    "#test = removeStopwords(dfAPI['body'], stopwords)\n",
    "test = removeStopwords([' yah I got nutty and bought $QS'], stopwords)\n",
    "#test = removeStopwords(dfAPI.iloc[0, 2], stopwords)\n",
    "#text_list = dfAPI['body'].tolist()\n",
    "#test = removeStopwords(text_list, stopwords)\n",
    "\n",
    "print(dfAPI.iloc[0,2],'\\n')\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#420 method that sorts tuples by second term\n",
    "# https://www.geeksforgeeks.org/python-program-to-sort-a-list-of-tuples-by-second-item/\n",
    "# Python program to sort a list of tuples by the second Item using sort()  \n",
    "# Function to sort the list by second item of tuple \n",
    "\n",
    "def Sort_Tuple(tup):  \n",
    "  \n",
    "    # reverse = None (Sorts in Ascending order)  \n",
    "    # key is set to sort using second element of sublist lambda has been used  \n",
    "    \n",
    "    tup.sort(key = lambda x: x[1])  \n",
    "    tup.reverse()\n",
    "    return tup  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#440\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pstri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#450\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "#460\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "print(len(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pstri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#440\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#450\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "#460\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "print(len(stopWords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'against', 'd', 'they', 'an', 'can', 'her', 'further', 'm', 'there', 've', 'where', 'in', \"you'd\", 'mustn', 'but', \"wouldn't\", 're', 'through', \"aren't\", 'those', 'did', 'some', 'ours', 'will', 'such', \"couldn't\", 'and', 'only', \"needn't\", 'has', 'why', 'other', 'our', \"weren't\", 'few', 'very', 'isn', 'ma', 'didn', \"hasn't\", 'does', \"that'll\", 'too', \"isn't\", 'myself', 't', 'so', 'won', 'be', 'was', 'by', 'more', \"didn't\", 'his', 'itself', 'a', 'most', 'off', 'this', 'again', \"she's\", 'am', 'here', 'below', 'not', 'mightn', 'what', 'weren', 'of', 'out', 'over', \"won't\", \"mustn't\", 'himself', 'yours', 'being', 'as', 'just', 'its', \"don't\", 'herself', 'me', 'whom', 'been', 'these', 'during', 'once', 'all', \"wasn't\", 'yourself', 'own', 'their', 'hasn', \"you're\", 'until', 'under', 'your', 'into', 'i', 'don', 'll', \"shouldn't\", 'theirs', 'are', \"it's\", 'needn', 'were', 'couldn', 'had', 'yourselves', 'any', 'doesn', 'have', 'now', \"you've\", 'same', 'wouldn', 'no', 'the', 'ourselves', 'if', 'o', 'with', 'hers', 'down', 'up', 'should', 'shouldn', 'than', 'before', 'for', 'do', 's', 'we', 'shan', 'from', 'both', 'she', 'themselves', 'about', 'my', 'on', 'after', 'he', 'when', \"hadn't\", 'then', 'it', 'above', 'nor', 'to', \"should've\", 'wasn', 'because', 'haven', \"you'll\", 'aren', 'or', 'between', 'is', \"mightn't\", 'which', 'hadn', 'them', 'y', 'how', 'at', 'each', 'while', 'that', \"doesn't\", \"haven't\", 'doing', \"shan't\", 'ain', 'having', 'you', 'who', 'him'}\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "print(stopWords)\n",
    "print(len(stopWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n",
      "['!', '#', '$', '%', '&', \"'\", ',', '.', '39', '41.75', '530.05', ';', '?', '@', '[Screenshot]', '[SCREENSHOT]', '[screenshot]', '[Screenshot]Great', 'a', 'AAPL', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'ain', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'AMC', 'AMD', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'aren', \"aren't\", 'ARK', 'around', 'ARWR', 'as', 'at', 'BA', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'Been', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldn', \"couldn't\", 'couldnt', 'cry', 'CSCO', 'd', 'DD', 'de', 'describe', 'detail', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'FB', 'few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'GME', 'go', 'GOOG', 'GOOGL', 'got', 'Got', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'hasnt', 'have', 'haven', \"haven't\", 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'I', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'INFI', 'INTC', 'Intel', 'intel', 'interest', 'into', 'is', 'isn', \"isn't\", 'It', 'it', \"it's\", 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'll', 'ltd', 'm', 'ma', 'Maddog68', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mightn', \"mightn't\", 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'moving', 'MU', 'much', 'must', 'mustn', \"mustn't\", 'my', 'myself', 'name', 'namely', 'needn', \"needn't\", 'neither', 'never', 'nevertheless', 'next', 'nine', 'NIO', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'nutty', 'NVDA', 'o', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'PHOTONICS', 'please', 'POETF', 'put', 'QS', 'rather', 're', 'Readytogo123', 's', 'same', 'Screenshot', 'screenshot', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'SMART', 'SMH', 'So', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'Stocktwits', 'such', 'system', 't', 'T', 'take', 'ten', 'than', 'that', \"that'll\", 'The', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'today', 'together', 'too', 'top', 'toward', 'towards', 'TSLA', 'TSM', 'twelve', 'twenty', 'two', 'Two', 'un', 'under', 'until', 'up', 'upon', 'us', 've', 'very', 'via', 'was', 'wasn', \"wasn't\", 'we', 'weeks', 'well', 'were', 'weren', \"weren't\", 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'won', \"won't\", 'would', 'wouldn', \"wouldn't\", 'y', 'yah', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "#470 creates a list of new stopwords and then adds them to the set provided by nltk\n",
    "# Note: it is case sensitive\n",
    "\n",
    "\n",
    "newStopWords = ['a', 'about', 'above', 'across', 'after', 'afterwards']\n",
    "newStopWords += ['again', 'against', 'all', 'almost', 'alone', 'along']\n",
    "newStopWords += ['already', 'also', 'although', 'always', 'am', 'among']\n",
    "newStopWords += ['amongst', 'amoungst', 'amount', 'an', 'and', 'another']\n",
    "newStopWords += ['any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere']\n",
    "newStopWords += ['are', 'around', 'as', 'at', 'back', 'be', 'became']\n",
    "newStopWords += ['because', 'become', 'becomes', 'becoming', 'been']\n",
    "newStopWords += ['before', 'beforehand', 'behind', 'being', 'below']\n",
    "newStopWords += ['beside', 'besides', 'between', 'beyond', 'bill', 'both']\n",
    "newStopWords += ['bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant']\n",
    "newStopWords += ['co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de']\n",
    "newStopWords += ['describe', 'detail', 'did', 'do', 'done', 'down', 'due']\n",
    "newStopWords += ['during', 'each', 'eg', 'eight', 'either', 'eleven', 'else']\n",
    "newStopWords += ['elsewhere', 'empty', 'enough', 'etc', 'even', 'ever']\n",
    "newStopWords += ['every', 'everyone', 'everything', 'everywhere', 'except']\n",
    "newStopWords += ['few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first']\n",
    "newStopWords += ['five', 'for', 'former', 'formerly', 'forty', 'found']\n",
    "newStopWords += ['four', 'from', 'front', 'full', 'further', 'get', 'give']\n",
    "newStopWords += ['go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her']\n",
    "newStopWords += ['here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers']\n",
    "newStopWords += ['herself', 'him', 'himself', 'his', 'how', 'however']\n",
    "newStopWords += ['hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed']\n",
    "newStopWords += ['interest', 'into', 'is', 'it', 'its', 'itself', 'keep']\n",
    "newStopWords += ['last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made']\n",
    "newStopWords += ['many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine']\n",
    "newStopWords += ['more', 'moreover', 'most', 'mostly', 'move', 'much']\n",
    "newStopWords += ['must', 'my', 'myself', 'name', 'namely', 'neither', 'never']\n",
    "newStopWords += ['nevertheless', 'next', 'nine', 'nobody', 'none'] #removed 'no'\n",
    "newStopWords += ['noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of']\n",
    "newStopWords += ['off', 'often', 'on','once', 'one', 'only', 'onto', 'or']\n",
    "newStopWords += ['other', 'others', 'otherwise', 'our', 'ours', 'ourselves']\n",
    "newStopWords += ['out', 'over', 'own', 'part', 'per', 'perhaps', 'please']\n",
    "newStopWords += ['put', 'rather', 're', 's', 'same', 'see', 'seem', 'seemed']\n",
    "newStopWords += ['seeming', 'seems', 'serious', 'several', 'she', 'should']\n",
    "newStopWords += ['show', 'side', 'since', 'sincere', 'six', 'sixty', 'so']\n",
    "newStopWords += ['some', 'somehow', 'someone', 'something', 'sometime']\n",
    "newStopWords += ['sometimes', 'somewhere', 'still', 'such', 'system', 'take']\n",
    "newStopWords += ['ten', 'than', 'that', 'the', 'their', 'them', 'themselves']\n",
    "newStopWords += ['then', 'thence', 'there', 'thereafter', 'thereby']\n",
    "newStopWords += ['therefore', 'therein', 'thereupon', 'these', 'they']\n",
    "newStopWords += ['thick', 'thin', 'third', 'this', 'those', 'though', 'three']\n",
    "newStopWords += ['three', 'through', 'throughout', 'thru', 'thus', 'to']\n",
    "newStopWords += ['together', 'too', 'top', 'toward', 'towards', 'twelve']\n",
    "newStopWords += ['twenty', 'two', 'un', 'under', 'until', 'up', 'upon']\n",
    "newStopWords += ['us', 'very', 'via', 'was', 'we', 'well', 'were', 'what']\n",
    "newStopWords += ['whatever', 'when', 'whence', 'whenever', 'where']\n",
    "newStopWords += ['whereafter', 'whereas', 'whereby', 'wherein', 'whereupon']\n",
    "newStopWords += ['wherever', 'whether', 'which', 'while', 'whither', 'who']\n",
    "newStopWords += ['whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with']\n",
    "newStopWords += ['within', 'without', 'would', 'yet', 'you', 'your']\n",
    "newStopWords += ['yours', 'yourself', 'yourselves'] #provided by Codecademy??\n",
    "\n",
    "# additional stopwords:\n",
    "newStopWords += ['[Screenshot]', '[screenshot]', 'Screenshot', '[Screenshot]Great', '[SCREENSHOT]', 'screenshot', \n",
    "                 'The', 'the', 'SMART', 'yah', 'got', 'nutty', 'moving', 'weeks', 'Got', 'So', 'today', 'Been', 'or']\n",
    "\n",
    "newStopWords += ['I', 'it', 'It'] # pronouns\n",
    "\n",
    "newStopWords += ['AMD', 'NVDA','NVDA', 'TSLA', 'GOOG', 'BA', 'FB', 'GOOGL', 'INTC', 'intel', 'Intel', 'CSCO', 'MU', \n",
    "                 'SMH', 'TSM','AAPL', 'TSLA', 'CSCO', 'POETF', 'PHOTONICS', 'DD', 'ARWR', 'T', 'INFI', 'AMC', 'ARK',\n",
    "                'GME', 'NIO', 'QS'] # Stock symbols or names\n",
    "\n",
    "newStopWords += ['Readytogo123', 'Maddog68','Stocktwits'] # nouns\n",
    "\n",
    "newStopWords += ['.', '?', '!', ';', ',', \"'\"] # punctuation\n",
    "\n",
    "newStopWords += ['&', '#', '%', '$', '@'] # symbols\n",
    "\n",
    "newStopWords += ['41.75', '530.05', '39', 'Two', 'two',] # numbers\n",
    "\n",
    "#adds them to the stopWords list provided by nltk\n",
    "for i in newStopWords:\n",
    "    stopWords.add(i) #stopWords is defined as a \"set\" in #450 when inputed as english words from nltk;\n",
    "    # sets cannot be ordered so it must be converted back to a list to be ordered or alphabetized. A set has no duplicate elements.\n",
    "\n",
    "print(len(stopWords))\n",
    "#print(stopWords)\n",
    "\n",
    "#converts the set to a list\n",
    "stopWords_list = list(stopWords)\n",
    "\n",
    "#sorts the stopword list\n",
    "stopWords_list.sort(key = lambda k : k.lower())\n",
    "print(stopWords_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stopWords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '#', '$', '%', '&', \"'\", ',', '.', '39', '41.75', '530.05', ';', '?', '@', '[Screenshot]', '[SCREENSHOT]', '[screenshot]', '[Screenshot]Great', 'a', 'AAPL', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'ain', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'AMC', 'AMD', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'aren', \"aren't\", 'ARK', 'around', 'ARWR', 'as', 'at', 'BA', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'Been', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldn', \"couldn't\", 'couldnt', 'cry', 'CSCO', 'd', 'DD', 'de', 'describe', 'detail', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'FB', 'few', 'fifteen', 'fifty', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'GME', 'go', 'GOOG', 'GOOGL', 'got', 'Got', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'hasnt', 'have', 'haven', \"haven't\", 'having', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'I', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'INFI', 'INTC', 'Intel', 'intel', 'interest', 'into', 'is', 'isn', \"isn't\", 'It', 'it', \"it's\", 'its', 'itself', 'just', 'keep', 'last', 'latter', 'latterly', 'least', 'less', 'll', 'ltd', 'm', 'ma', 'Maddog68', 'made', 'many', 'may', 'me', 'meanwhile', 'might', 'mightn', \"mightn't\", 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'moving', 'MU', 'much', 'must', 'mustn', \"mustn't\", 'my', 'myself', 'name', 'namely', 'needn', \"needn't\", 'neither', 'never', 'nevertheless', 'next', 'nine', 'NIO', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'nutty', 'NVDA', 'o', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'PHOTONICS', 'please', 'POETF', 'put', 'QS', 'rather', 're', 'Readytogo123', 's', 'same', 'Screenshot', 'screenshot', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'SMART', 'SMH', 'So', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'Stocktwits', 'such', 'system', 't', 'T', 'take', 'ten', 'than', 'that', \"that'll\", 'The', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'today', 'together', 'too', 'top', 'toward', 'towards', 'TSLA', 'TSM', 'twelve', 'twenty', 'two', 'Two', 'un', 'under', 'until', 'up', 'upon', 'us', 've', 'very', 'via', 'was', 'wasn', \"wasn't\", 'we', 'weeks', 'well', 'were', 'weren', \"weren't\", 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'won', \"won't\", 'would', 'wouldn', \"wouldn't\", 'y', 'yah', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# this also works; from same link as above\\nWordsToBeRem = ['no', 'mill']\\nfor remword in list(stopWords):\\n    if remword in WordsToBeRem:\\n        stopWords_list.remove(remword)\\n\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#480 This removes words from the list of stopwords and writes list to csv file\n",
    "# https://stackoverflow.com/questions/29771168/how-to-remove-words-from-a-list-in-python#:~:text=one%20more%20easy%20way%20to%20remove%20words%20from,%3D%20words%20-%20stopwords%20final_list%20%3D%20list%20%28final_list%29\n",
    "#new_words = list(filter(lambda w: w not in stop_words, initial_words))\n",
    "\n",
    "WordsToBeRem = ['no']\n",
    "stopWords = list(filter(lambda w: w not in WordsToBeRem, stopWords_list)) #stopWords_list has been sorted in #470\n",
    "\n",
    "#converts the stopword list to a df and then outputs the df to a csv file\n",
    "df_stopwords = pd.DataFrame(stopWords, columns = ['stopwords'])\n",
    "\n",
    "df_stopwords.to_csv('stopwords.csv', index = False)\n",
    "\n",
    "\n",
    "print(stopWords)\n",
    "\n",
    "'''\n",
    "# this also works; from same link as above\n",
    "WordsToBeRem = ['no', 'mill']\n",
    "for remword in list(stopWords):\n",
    "    if remword in WordsToBeRem:\n",
    "        stopWords_list.remove(remword)\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It did remove the words from the stopWords list!\n"
     ]
    }
   ],
   "source": [
    "#490 Checks to see of the words were removed from the stopWords list.\n",
    "r = 0\n",
    "\n",
    "for w in stopWords:\n",
    "    #print(w)\n",
    "    if w in WordsToBeRem:\n",
    "        print('The word ', w , ' is still in the stopWords list!')\n",
    "        r += 1\n",
    "\n",
    "if r == 0:\n",
    "    print('It did remove the words from the stopWords list!')\n",
    "    \n",
    "#print(len(stopWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make functions to run on entire df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-02-23T18:37:55Z   \n",
      "1   INTC  2021-02-23T18:10:05Z   \n",
      "2   INTC  2021-02-23T17:41:45Z   \n",
      "3   INTC  2021-02-23T17:36:25Z   \n",
      "4   INTC  2021-02-23T16:55:34Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0  $GOOG $BA $FB $GOOGL $INTC ..Wow _Great !!📈 ga...         1      None   \n",
      "1  $TSLA chart looking like $INTC or $CSCO from t...         1   Bearish   \n",
      "2  $POETF PHOTONICS. Come take a peek. Quick DD a...        33   Bullish   \n",
      "3  $ARWR $INTC $T $INFI added to all of these tod...       261   Bullish   \n",
      "4  $INTC Third Point Sees Enormous Shareholder Va...        12   Bullish   \n",
      "\n",
      "   raw_compound  compound_bin  sentiment_number  modified_rating modified?  \n",
      "0        0.7243           1.0               0.0              1.0       Yes  \n",
      "1        0.3612           1.0              -1.0             -1.0        No  \n",
      "2        0.7184           1.0               1.0              1.0        No  \n",
      "3        0.0000           0.0               1.0              1.0        No  \n",
      "4        0.5423           1.0               1.0              1.0        No  \n"
     ]
    }
   ],
   "source": [
    "#500\n",
    "print(dfAPI.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-03-05T20:51:14Z   \n",
      "1   INTC  2021-03-05T20:06:56Z   \n",
      "2   INTC  2021-03-05T19:57:20Z   \n",
      "3   INTC  2021-03-05T19:52:43Z   \n",
      "4   INTC  2021-03-05T19:44:47Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0                              common follow ur sibs        48   Bullish   \n",
      "1                                 ITT ADBE OPTT GLBS       575   Bullish   \n",
      "2  Should thankful bull market Dow couple reachin...        21   Bullish   \n",
      "3  ButterFingerDROPs sell October Still probably ...        77      None   \n",
      "4           Trading easy Buy Short signals real time       162      None   \n",
      "\n",
      "   raw_compound  compound_bin  sentiment_number  modified_rating modified?  \n",
      "0        0.0000           0.0               1.0                0        No  \n",
      "1        0.0000           0.0               1.0                0        No  \n",
      "2        0.6996           1.0               1.0                0        No  \n",
      "3        0.0000           0.0               0.0                0        No  \n",
      "4        0.4404           1.0               0.0                0        No  \n"
     ]
    }
   ],
   "source": [
    "#510 Removes stopwords from all the \"body\" text (tweets); to do this it must tokenize the string which means it must parse \n",
    "# the string into individual words. It then compares the words with the words in the stopwords list and if there is not \n",
    "# match it puts the word into the \"wordsFiltered\" list. It keeps appending to the list until all of the words are checked.\n",
    "# It then joins the individual words back into a string.\n",
    "\n",
    "#There is a difference between \"deep\" copy and \"shallow\" copy. \"Deep\" copy make a copy where the index and data are\n",
    "# separate from the original. \"Shallow\" copy is like a pointer where the two df share a common index and data\n",
    "#dfAPIScrubbed = dfAPI #This is a shallow copy\n",
    "\n",
    "dfAPIScrubbed = dfAPI.copy() #This is a deep copy. dfAPI.copy(deep = True); deep = True is default\n",
    "\n",
    "i = 0\n",
    "while i < len(dfAPI):\n",
    "    \n",
    "    data = dfAPI.iloc[i,2]\n",
    "    words = word_tokenize(data)\n",
    "    wordsFiltered = []\n",
    "\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            wordsFiltered.append(w)\n",
    "    \n",
    "    joinedWordsFiltered = ' '.join(wordsFiltered)\n",
    "    \n",
    "    dfAPIScrubbed.iloc[i,2] = joinedWordsFiltered # replaces the recorded in dfAPIScrubbed with the stopWords removed\n",
    "    # from the 'body'\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "#print(wordsFiltered)\n",
    "\n",
    "print(dfAPIScrubbed.head())\n",
    "\n",
    "#print(joinedWordsFiltered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AMD common follow ur sibs $INTC $MU\n",
      "common follow ur sibs\n"
     ]
    }
   ],
   "source": [
    "#compares the first record (index = 0) raw data (\"body\" column) with scrubbed (stopwords removed) data\n",
    "\n",
    "print(dfAPI.iloc[0,2])\n",
    "print(dfAPIScrubbed.iloc[0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of compound_bin scores that are different than the modified_rating: 749\n",
      "The total number of records is: 1291\n"
     ]
    }
   ],
   "source": [
    "#530 Compares the compound_bin[6] (nltk) to the modified_rating[8] (modified_rating is where the \"none\" or '0.0' rating\n",
    "#is re-assessed. this was done  to account for tweets where the person had a sentiment but did not bother \n",
    "#to input a sentiment)\n",
    "\n",
    "i = 0\n",
    "counter = 0\n",
    "\n",
    "while i < len(dfAPIScrubbed):\n",
    "    #if dfAPIScrubbed.iloc[i, 6] / 10 - dfAPIScrubbed.iloc[i, 7] != 0:\n",
    "    if dfAPIScrubbed.iloc[i, 6] - int((dfAPIScrubbed.iloc[i, 8])) != 0: # column 6 is 'compound_bin'; 8 is 'modified_rating'\n",
    "\n",
    "        #print(i, int(dfAPIScrubbed.iloc[i, 6]), int((dfAPIScrubbed.iloc[i, 8])))\n",
    "        counter += 1\n",
    "    i += 1\n",
    "print('The number of compound_bin scores that are different than the modified_rating:', counter)\n",
    "print('The total number of records is:', len(dfAPIScrubbed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the index number.:100\n",
      "While yesterday’s market action looks ominous  I would like to remind people that the federal government will approve another 1.9 billion of stimulus  more than $2.5B in 2 months.  The fed will continue to buy treasuries and for that reason you should not care about the 10 year note.  Much of this stimulus will end up back in the market.  The smartmoney have this completely wrong.  ..Despite the huge drop yesterday  I am still up 36% in 2021.  If you can afford to  take advantage of the sales.  Here are my main holdings and the performance since 4th qtr. 2020; not including INTC. ..Buy the fear!..SBH 66.6%.$PRTY 187.7%.$PERI 184.2%.AOSL 163.7%.ACLS 66.2%.$PRPL 44.0%.$FNF 23.3%.$INTC 23.9%\n",
      "While yesterday ’ market action looks ominous like remind people federal government approve 1.9 billion stimulus 2.5B 2 months fed continue buy treasuries reason care 10 year note Much stimulus end market smartmoney completely wrong .. Despite huge drop yesterday 36 2021 If afford advantage sales Here main holdings performance 4th qtr 2020 including .. Buy fear .. SBH 66.6 PRTY 187.7 PERI 184.2 .AOSL 163.7 .ACLS 66.2 PRPL 44.0 FNF 23.3 23.9\n",
      "Original nltk sentiment: -0.1\n",
      "Scrubbed nltk sentiment: 1.0\n"
     ]
    }
   ],
   "source": [
    "#540 Pulls up the record of interest; you must enter the index number.\n",
    "\n",
    "index = int(input('Enter the index number.:')) \n",
    "\n",
    "print(dfAPI.iloc[index,2])\n",
    "print(dfAPIScrubbed.iloc[index,2])\n",
    "\n",
    "print('Original nltk sentiment:', dfAPI.iloc[index,6] / 10)\n",
    "print('Scrubbed nltk sentiment:', dfAPIScrubbed.iloc[index,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$HPQ amazing beat $spy $NVDA $INTC\n",
      "HPQ amazing beat spy\n"
     ]
    }
   ],
   "source": [
    "# compares the pre-scrubbed body with the post-scrubbed body (stopwords removed)\n",
    "print(dfAPI.iloc[334,2])\n",
    "print(dfAPIScrubbed.iloc[334,2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create new model with scrubbed body data (stopwords removed). It can be run with new labels (sentiments) that were generated with nltk Vader or that are from the stocktwits sentiment scores with the \"None\" sentiment ratings re-evaluated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#550 converts the scrubbed_compound scores into a 1 significant figure integer from a float number; rounding up\n",
    "# this is only needed if you are going to uses the 'scrubbed_compound' value as the label.\n",
    "dfAPIScrubbed['scrubbed_compound'] =  np.int64((dfAPIScrubbed['scrubbed_compound'] + .05) * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     symbol            created_at  \\\n",
      "0      INTC  2021-02-23T18:37:55Z   \n",
      "1      INTC  2021-02-23T18:10:05Z   \n",
      "2      INTC  2021-02-23T17:41:45Z   \n",
      "3      INTC  2021-02-23T17:36:25Z   \n",
      "4      INTC  2021-02-23T16:55:34Z   \n",
      "...     ...                   ...   \n",
      "1275     MU  2021-02-01T20:10:14Z   \n",
      "1276     MU  2021-02-01T20:07:12Z   \n",
      "1277     MU  2021-02-01T19:40:37Z   \n",
      "1278     MU  2021-02-01T19:37:10Z   \n",
      "1279     MU  2021-02-01T19:25:26Z   \n",
      "\n",
      "                                                   body followers sentiment  \\\n",
      "0     .. Wow _Great 📈 gains 2490 15 returns A big th...         1      None   \n",
      "1                        chart looking like tech bubble         1   Bearish   \n",
      "2     Come peek Quick bet pull trigger couple grand ...        33   Bullish   \n",
      "3                      added If gets cheaper write puts       261   Bullish   \n",
      "4     Third Point Sees Enormous Shareholder Value Cr...        12   Bullish   \n",
      "...                                                 ...       ...       ...   \n",
      "1275  As reported recent earnings calls Semiconducto...       126   Bullish   \n",
      "1276  gap hold long managed needed support prior day...        43      None   \n",
      "1277  leading way 3.7 ARKK leading team 3.2 3 MRVL 2...       353   Bullish   \n",
      "1278     Hell yes actually work 9-5 job came meeting 80        55   Bullish   \n",
      "1279                                  OMFG 80 going ...        64      None   \n",
      "\n",
      "      raw_compound  compound_bin  sentiment_number  modified_rating modified?  \\\n",
      "0           0.7243           1.0               0.0              1.0       Yes   \n",
      "1           0.3612           1.0              -1.0             -1.0        No   \n",
      "2           0.7184           1.0               1.0              1.0        No   \n",
      "3           0.0000           0.0               1.0              1.0        No   \n",
      "4           0.5423           1.0               1.0              1.0        No   \n",
      "...            ...           ...               ...              ...       ...   \n",
      "1275        0.3129           1.0               1.0              1.0        No   \n",
      "1276       -0.5023          -1.0               0.0              1.0       Yes   \n",
      "1277       -0.4648          -1.0               1.0              1.0        No   \n",
      "1278       -0.4404          -1.0               1.0              1.0        No   \n",
      "1279        0.0000           0.0               0.0             -1.0       Yes   \n",
      "\n",
      "      scrubbed_compound  scrubbed_compound_bin  \n",
      "0                     8                      8  \n",
      "1                     4                      4  \n",
      "2                     7                      7  \n",
      "3                     0                      0  \n",
      "4                     5                      5  \n",
      "...                 ...                    ...  \n",
      "1275                  1                      1  \n",
      "1276                 -3                     -3  \n",
      "1277                  0                      0  \n",
      "1278                 -3                     -3  \n",
      "1279                  0                      0  \n",
      "\n",
      "[1280 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# 550 converts the 'scrubbed_compound' (column 10) data to either a 1, 0 or -1.  \n",
    "# if nltk sentiment number are >= .1; 0 if -.1 < x < .1 and -1 if <= -.1 and over-rights the value in compound_bin\n",
    "# creates a new column called 'compound_bin' from the raw_compound scores\n",
    "\n",
    "dfAPIScrubbed['scrubbed_compound_bin'] = dfAPIScrubbed['scrubbed_compound'] # creates a new column 'scrubbed_compound_bin' (column 11)\n",
    "\n",
    "i = 0\n",
    "while i < len(dfAPI):\n",
    "    if dfAPIScrubbed.iloc[i,10] >= 0.1: # column 10 is 'scrubbed_compound'\n",
    "        dfAPIScrubbed.iloc[i, 11] =  np.int(dfAPIScrubbed.iloc[i, 10] + .9) # column 11 is 'scurbbed_compound_bin'\n",
    "        \n",
    "    if dfAPIScrubbed.iloc[i,10] < .1 and dfAPIScrubbed.iloc[i, 10] > -.1:\n",
    "        dfAPIScrubbed.iloc[i, 11] = 0   \n",
    "        \n",
    "    if dfAPIScrubbed.iloc[i,10] <= -.1:\n",
    "        dfAPIScrubbed.iloc[i, 11] =  np.int(dfAPIScrubbed.iloc[i, 10] - .9)\n",
    "    i += 1\n",
    "    \n",
    "print(dfAPIScrubbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-02-23T18:37:55Z   \n",
      "1   INTC  2021-02-23T18:10:05Z   \n",
      "2   INTC  2021-02-23T17:41:45Z   \n",
      "3   INTC  2021-02-23T17:36:25Z   \n",
      "4   INTC  2021-02-23T16:55:34Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0  .. Wow _Great 📈 gains 2490 15 returns A big th...         1      None   \n",
      "1                     chart looking like tech bubble         1   Bearish   \n",
      "2  Come peek Quick bet pull trigger couple grand ...        33   Bullish   \n",
      "3                   added If gets cheaper write puts       261   Bullish   \n",
      "4  Third Point Sees Enormous Shareholder Value Cr...        12   Bullish   \n",
      "\n",
      "   raw_compound  compound_bin  sentiment_number  modified_rating modified?  \\\n",
      "0        0.7243           1.0               0.0              1.0       Yes   \n",
      "1        0.3612           1.0              -1.0             -1.0        No   \n",
      "2        0.7184           1.0               1.0              1.0        No   \n",
      "3        0.0000           0.0               1.0              1.0        No   \n",
      "4        0.5423           1.0               1.0              1.0        No   \n",
      "\n",
      "   scrubbed_compound  scrubbed_compound_bin  \n",
      "0             0.8271                    1.0  \n",
      "1             0.3612                    1.0  \n",
      "2             0.7184                    1.0  \n",
      "3             0.0000                    0.0  \n",
      "4             0.5423                    1.0  \n"
     ]
    }
   ],
   "source": [
    "print(dfAPIScrubbed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol            created_at  \\\n",
      "0   INTC  2021-02-23T18:37:55Z   \n",
      "1   INTC  2021-02-23T18:10:05Z   \n",
      "2   INTC  2021-02-23T17:41:45Z   \n",
      "3   INTC  2021-02-23T17:36:25Z   \n",
      "4   INTC  2021-02-23T16:55:34Z   \n",
      "\n",
      "                                                body followers sentiment  \\\n",
      "0  .. Wow _Great 📈 gains 2490 15 returns A big th...         1      None   \n",
      "1                     chart looking like tech bubble         1   Bearish   \n",
      "2  Come peek Quick bet pull trigger couple grand ...        33   Bullish   \n",
      "3                   added If gets cheaper write puts       261   Bullish   \n",
      "4  Third Point Sees Enormous Shareholder Value Cr...        12   Bullish   \n",
      "\n",
      "   raw_compound  compound_bin  sentiment_number  modified_rating modified?  \\\n",
      "0        0.7243           1.0               0.0              1.0       Yes   \n",
      "1        0.3612           1.0              -1.0             -1.0        No   \n",
      "2        0.7184           1.0               1.0              1.0        No   \n",
      "3        0.0000           0.0               1.0              1.0        No   \n",
      "4        0.5423           1.0               1.0              1.0        No   \n",
      "\n",
      "   scrubbed_compound  scrubbed_compound_bin  \n",
      "0                  8                      8  \n",
      "1                  4                      4  \n",
      "2                  7                      7  \n",
      "3                  0                      0  \n",
      "4                  5                      5  \n"
     ]
    }
   ],
   "source": [
    "#610\n",
    "print(dfAPIScrubbed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#620\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of file 1 is: 1291\n",
      "The length of file 2 is: 1280\n",
      "The length of the combined dataframe is: 2571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'load = input(\\'Is this the first time processing the raw stocktwits data (enter \"n\"/\"N\" or \"y\"/\"Y\")? \\')\\nif load == \\'n\\' or load == \\'N\\' or load == \\'no\\' or load == \\'No\\':\\n    dfAPI = getData(filename)\\n    print(\\'Loaded filename:\\', filename)\\nelse:\\n    \\n    print(\\'ok\\')\\n    '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 650 Loads and combines two different dataframes in dfAPI\n",
    "\n",
    "filename1 = \"tech stockTwit 03112021 adjusted-Copy1.csv\"\n",
    "filename2 = \"tech stockTwit 02232021 adjusted-Copy1.csv\"\n",
    "\n",
    "dfAPI1 = getData(filename1)\n",
    "dfAPI2 = getData(filename2)\n",
    "\n",
    "dfAPI = dfAPI1.append(dfAPI2)\n",
    "\n",
    "print('The length of file 1 is:', len(dfAPI1))\n",
    "print('The length of file 2 is:', len(dfAPI2))\n",
    "\n",
    "print('The length of the combined dataframe is:', len(dfAPI))\n",
    "\n",
    "\n",
    "'''load = input('Is this the first time processing the raw stocktwits data (enter \"n\"/\"N\" or \"y\"/\"Y\")? ')\n",
    "if load == 'n' or load == 'N' or load == 'no' or load == 'No':\n",
    "    dfAPI = getData(filename)\n",
    "    print('Loaded filename:', filename)\n",
    "else:\n",
    "    \n",
    "    print('ok')\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The csv file was written. File name:  tech stockTwit 03112021 dup advert stopwords.csv\n"
     ]
    }
   ],
   "source": [
    "filename_output = 'tech stockTwit 03112021 dup advert stopwords.csv'\n",
    "dfAPIScrubbed.to_csv(filename_output, index = False)\n",
    "#dfAPI.to_csv(filename_output, index = False)\n",
    "print('The csv file was written. File name: ', filename_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
